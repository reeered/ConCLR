global:
  name: exp
  phase: train
  workdir: runs
  seed: ~
 
dataset:
  root: 'data/mnt/ramdisk/max/90kDICT32px'
  train: {
    labels: 'data/mnt/ramdisk/max/90kDICT32px/annotation_train_ml13.txt',
    batch_size: 128
  }
  test: {
    labels: 'data/mnt/ramdisk/max/90kDICT32px/annotation_test_ml13.txt',
    batch_size: 128
  }
  charset_path: data/charset_36.txt
  num_workers: 4
  max_length: 25
  image_height: 32
  image_width: 128
  multiscales: False
  pin_memory: True
  smooth_label: False
  smooth_factor: 0.1
  one_hot_y: True
  use_sm: False

training:
  epochs: 6
  show_iters: 50
  eval_iters: 3000
  save_iters: 20000
  start_iters: 0
  stats_iters: 100000

optimizer:
  type: Adadelta # Adadelta, Adam, SGD
  args: {
    # betas: !!python/tuple [0.9, 0.99], # betas=(0.9,0.99) for AdamW
    # betas: !!python/tuple [0.9, 0.999], # for default Adam 
  }
  lr: 0.0001

model:
  checkpoint: ~
  strict: True
