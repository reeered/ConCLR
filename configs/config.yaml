global:
  name: ConCLR
  phase: train
  workdir: runs
  seed: ~
 
dataset:
  root: 'data/mnt/ramdisk/max/90kDICT32px'
  train: {
    labels: 'data/mnt/ramdisk/max/90kDICT32px/annotation_train_ml13.txt',
    batch_size: 8
  }
  test: {
    labels: 'data/mnt/ramdisk/max/90kDICT32px/annotation_test_ml13.txt',
    batch_size: 256
  }
  multiscales: False
  num_workers: 14

training:
  epochs: 10
  show_iters: 50
  eval_iters: 3000
  save_iters: 3000

optimizer:
  type: Adam
  lr: 0.0001
  args: 
    betas: !!python/tuple [0.9, 0.999] # for default Adam 

scheduler:
  type: CosineAnnealingLR
  T_max: 16000

model:
  checkpoint: checkpoints/best-pretrain-vision-model.pth
  loss_weight: 1
  attention: 'position'
  backbone: 'transformer'
  backbone_ln: 3

loss:
  type: 'ConCLR Loss'
  args: 
    omega: 0.5
    tau: 2.0
    lambda: 0.2
