{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genaxis theatre\n",
      "[06]\n",
      "62-03\n",
      "nothing?\n",
      "gen is\n",
      "$500\n",
      "$4.00\n",
      "$4.00\n",
      "$4.00\n",
      "!947\n",
      "minute;\n",
      "100,000\n",
      "day;\n",
      "36,000,000\n",
      "#ilovesciencecentre\n",
      "simge.edu.sg\n",
      "whole-grain\n",
      "children's\n",
      "one-north\n",
      "7-9pm\n",
      "11:1\n",
      "ratio.\n",
      "less?\n",
      "singapore's\n",
      "no.1\n",
      "there's\n",
      "10%\n",
      "$10\n",
      "more!\n",
      "internet/\n",
      "top-up\n",
      "cashcard/flashpay/\n",
      "now!\n",
      "#14-01\n",
      "#14-03\n",
      "1-5\n",
      "$1.00\n",
      "$7.90\n",
      "$20\n",
      "3 for\n",
      "$20.00\n",
      "pillow.\n",
      "non-fiction\n",
      "20%\n",
      "year!\n",
      "it's\n",
      "a...\n",
      "mia!\n",
      "side-gate\n",
      "6-3388-680\n",
      "#05-11\n",
      "www.tk-hair.com\n",
      "experts!\n",
      "$9.90\n",
      "$128\n",
      "$5,000\n",
      "(usp)\n",
      "1-12\n",
      "#10-12\n",
      "#10-10\n",
      "#10-15\n",
      "24/7\n",
      "$24\n",
      "season's\n",
      "m1-a1\n",
      "by:\n",
      "recycle!\n",
      "recycle!\n",
      "world's\n",
      "group's\n",
      "(cgdb)\n",
      "cgdb,\n",
      "(us$1,57\n",
      "billion)\n",
      "launch.\n",
      "6,000\n",
      "home.\n",
      "life!\n",
      "www.imob.sg\n",
      "10%\n",
      "me,\n",
      "life,\n",
      "#03-01/02/03\n",
      "good!\n",
      "$128\n",
      "world's\n",
      "we're\n",
      "10-10 to 11\n",
      "10-12 to 14\n",
      "10-15 to 16\n",
      "$10\n",
      "day.\n",
      "sexy!\n",
      "don't\n",
      "pte.\n",
      "ltd.\n",
      "$24\n",
      "singapore's\n",
      "3.3m\n",
      "reader\\\"\n",
      "side-gate\n",
      "residents,\n",
      "\\\"scan\\\"\n",
      "\\\"card\n",
      "gate.\n",
      "mcdonald's\n",
      "levi's\n",
      "out!\n",
      "to:\n",
      "\\\"we\n",
      "claims.\n",
      "lives.\\\"\n",
      "introducing..\n",
      "www.ite.edu.sg\n",
      "we´re\n",
      "s2.30\n",
      "$2..30\n",
      "$2.00\n",
      "shop&dine\n",
      "19 99\n",
      "182/182\n",
      "x-ing\n",
      "here!\n",
      "#05-11\n",
      "experts!\n",
      "4-hr\n",
      "jobstreet.com\n",
      "shell.\n",
      "introducucing...\n",
      "joy!\n",
      "toast?\n",
      "ham & cheese\n",
      "$2.50\n",
      "1.60\n",
      "1.50\n",
      "teas!!\n",
      "2.50\n",
      "3.50\n",
      "we're\n",
      "10-21\n",
      "[05]\n",
      "side-gate\n",
      "\\\"scan\\\"\n",
      "it´s\n",
      "delight's\n",
      "win:\n",
      "hi!\n",
      "datatalk$22\n",
      "top-up\n",
      "$264\n",
      "win:\n",
      "data/social\n",
      "chances:\n",
      "$0.50\n",
      "café\n",
      "jean y\n",
      "nature's\n",
      "you!\n",
      "pro-am\n",
      "singapore's\n",
      "www.sbl.sg\n",
      "hi-tec\n",
      "ol:lo\n",
      "world´s\n",
      "mc.2\n",
      "28.888\n",
      "full-flat\n",
      "1,888\n",
      "york'\n",
      "it.\n",
      "concierge@l3\n",
      "e-pay\n",
      "75%\n",
      "11:42\n",
      "oco ichibi\n",
      "70%\n",
      "15%\n",
      "l'occitane\n",
      "beauty's\n",
      "beauty's\n",
      "giordano/ladies\n",
      "50%\n",
      "santa's\n",
      "4g.\n",
      "can!\n",
      "dan brown\n",
      "jack's\n",
      "don't\n",
      "0-8\n",
      "season!\n",
      "29.90\n",
      "70%\n",
      "20%\n",
      "40%\n",
      "streetwise.\n",
      "20%\n",
      "10%\n",
      "70%\n",
      "i am\n",
      "12.50\n",
      "et 1\n",
      "-70\n",
      "www.tissot.cn\n",
      "victoria's\n",
      "victoria's\n",
      "70%\n",
      "50%\n",
      "sh o\n",
      "50%\n",
      "natures's\n",
      "50%\n",
      "50%\n",
      "50%\n",
      "now!\n",
      "sale!\n",
      "men's\n",
      "optical 88\n",
      "m&m's\n",
      "m&m\n",
      "m&m's\n",
      "m&ms\n",
      "new!\n",
      "gabu!\n",
      "milk!\n",
      "wine&spirits\n",
      "urg al\n",
      "students'\n",
      "#04-11\n",
      "yes!\n",
      "...\n",
      "j.k.\n",
      "children's\n",
      "$12\n",
      "$20\n",
      "girls'\n",
      "baby-g\n",
      "baby-g\n",
      "sale!\n",
      "tel:\n",
      "tel:\n",
      "f&n\n",
      "european h\n",
      "ld of sports\n",
      "$428\n",
      "$71\n",
      "$150\n",
      "privileges!\n",
      "25!\n",
      "do you note?\n",
      "movie,\n",
      "time,\n",
      "day.\n",
      "drop-off\n",
      "s on\n",
      "1600 mrs\n",
      "$10\n",
      "pastamania!\n",
      "2.35\n",
      "2.50\n",
      "hungry?\n",
      "biggie.\n",
      "tech@vogue\n",
      "tech@vogue\n",
      "$15\n",
      "$15\n",
      "$15\n",
      "$36\n",
      "$33\n",
      "$28\n",
      "route:\n",
      "superdrystore.\n",
      "superdry.\n",
      "us!\n",
      "ride@\n",
      "xpressflower.com\n",
      "full-time\n",
      "chiropractic:\n",
      "you'd\n",
      "live.\n",
      "l'occitane\n",
      "=b2-25\n",
      "superdry.\n",
      "- #01\n",
      "b2-k15\n",
      "world,\n",
      "here.\n",
      "$$120,000\n",
      "compare!\n",
      "4.20\n",
      "3.15\n",
      "3.15\n",
      "wall's\n",
      "long-lasting\n",
      "re           lles\n",
      "b  ata\n",
      "it's\n",
      "rubber!\n",
      "saladstop!\n",
      "(at\n",
      "th s\n",
      "home-grow\n",
      "marks&\n",
      "st.marc\n",
      "victoria's\n",
      "70%\n",
      "a's\n",
      "2015!\n",
      "$30\n",
      "70%\n",
      "50%\n",
      "$1990\n",
      "01-06\n",
      "don't\n",
      "run.\n",
      "pore!\n",
      "don't\n",
      "it's\n",
      "appetit!\n",
      "co.\n",
      "a-t\n",
      "vinci:\n",
      "50%\n",
      "$1.50\n",
      "19.90\n",
      "lobby a\n",
      "(i)\n",
      "now!\n",
      "victoria's\n",
      "levi's\n",
      "levi's\n",
      "levi's\n",
      "now!\n",
      "-70%\n",
      "b1/b3\n",
      "1/2\n",
      "b2-40/41\n",
      "it's\n",
      "it's\n",
      "g-star\n",
      "g-star\n",
      "c  mper\n",
      "i o n\n",
      "g-star\n",
      "g-star\n",
      "joe's\n",
      "l1/l2/l3/l4\n",
      "l1/l2/l3\n",
      "f. nielly\n",
      "#02-07\n",
      "semi-annual\n",
      "kikki.k\n",
      "on:sal\n",
      "on sale\n",
      "make-up\n",
      "blush!\n",
      "100%\n",
      "www.zerospot.com\n",
      "max.\n",
      "1.7m\n",
      "40,257\n",
      "stores,\n",
      "brands,\n",
      "$100\n",
      "off!\n",
      "70%\n",
      "i.mages\n",
      "here!\n",
      "here!\n",
      "ucno:12c6009\n",
      "attention!\n",
      "no:\n",
      "l'oreal\n",
      "$ 15\n",
      "#04-29\n",
      "$30\n",
      "prices!!\n",
      "discounts!!\n",
      "savings!!\n",
      "tel.\n",
      "no.:\n",
      "( +65) 6732 2900\n",
      "$10\n",
      "02-25\n",
      "counter/kitchen\n",
      "wanted:\n",
      "wanted;\n",
      "03-26\n",
      "02-46\n",
      "s.k\n",
      "$10\n",
      "s.k.\n",
      "$10\n",
      "$10\n",
      "#02-81\n",
      "02-59\n",
      "at:\n",
      "#01-26/27\n",
      "01-62\n",
      "50%\n",
      "b2-a7\n",
      "beauty's\n",
      "l10.\n",
      "11/12,\n",
      "b2/1/4/7/9\n",
      "lift.\n",
      "b-one\n",
      "b-one\n",
      "floors.\n",
      "#12-02\n",
      "br  al\n",
      "promotion!!\n",
      "20%\n",
      "ar.\n",
      "need!\n",
      "ntelligence.\n",
      "(upp\n",
      "$20\n",
      "$50\n",
      "day!\n",
      "sign-up\n",
      "hi-tec\n",
      "li-ning\n",
      "note?\n",
      "concierge@l3\n",
      "at high\n",
      "speeds.\n",
      "café\n",
      "ca.\n",
      "a/x\n",
      "run.\n",
      "cw3/cw4\n",
      "715/717\n",
      "pune centas\n",
      "-70 %\n",
      "$8,888\n",
      "$100,000\n",
      "fashi  g\n",
      "mouth-watering\n",
      "marina:square\n",
      "marina:square\n",
      "everyday!\n",
      "beanstro,\n",
      "#dont\n",
      "marks&\n",
      "st.marc\n",
      "@b1\n",
      "&dining!\n",
      "b1,\n",
      "marina:\n",
      "ena e\n",
      "level 3\n",
      "#gvsunteccity\n",
      "h&m\n",
      "sk-ii\n",
      "move.\n",
      "latu  e\n",
      "50% off\n",
      "70%\n",
      "-70%\n",
      "50%off\n",
      "01-15\n",
      "#01-15\n",
      "ai #\n",
      "thirsty?\n",
      "$10\n",
      "m&m\n",
      "mt.\n",
      "@smrt\n",
      "public.\n",
      "admission.\n",
      "public.\n",
      "admission.\n",
      "pay.\n",
      "it's\n",
      "it's\n",
      "victoria's\n",
      "there's\n",
      "live.\n",
      "$8.80\n",
      "50%\n",
      "dr.\n",
      "50%\n",
      "off!\n",
      "14-17\n",
      "roffey s\n",
      "b1-150-15\n",
      "9am-\n",
      "alk'\n",
      "10%\n",
      "10%\n",
      "it's\n",
      "tm lewin\n",
      "50%\n",
      "dr.\n",
      "gla    illo\n",
      "www.dintaifung.com.sg\n",
      "ben's\n",
      "up to\n",
      "st.\n",
      "st.\n",
      "o-factory\n",
      "50%\n",
      "skin!\n",
      "time!\n",
      "pl   ect\n",
      "advertisement space\n",
      "claim!\n",
      "way!\n",
      "victoria's\n",
      "lady's\n",
      "lady's\n",
      "pho    a\n",
      "w.e.\n",
      "w.e.\n",
      "w.e.\n",
      "#22\n",
      "sale!\n",
      "sale!\n",
      "sale!\n",
      "america.\n",
      "classics.\n",
      "bong.\n",
      "fore er\n",
      "victoria's\n",
      "victoria's\n",
      "victoria's\n",
      "victoria's\n",
      "victoria's\n",
      ".50\n",
      "$5,50\n",
      "#b2-02/03\n",
      "70%off\n",
      "$100\n",
      "70%off\n",
      "$108\n",
      "$150\n",
      "@emerold\n",
      "crate&barrel\n",
      "blush!\n",
      "straps,\n",
      "$10\n",
      "omg!\n",
      "#01-12\n",
      "shopping!\n",
      "313@somerset\n",
      "marché\n",
      "asia's\n",
      "sk-ii\n",
      "january 8\n",
      "gentlemen's\n",
      "fleshimp.\n",
      "www.\n",
      "singapore's\n",
      "president's\n",
      "bit.\n",
      "care.\n",
      "che  s\n",
      "00:00 9\n",
      "women's\n",
      "us.\n",
      "60%\n",
      "face+\n",
      "6636-5830\n",
      "#b1-39\n",
      "j&d\n",
      "www.ywgroup.com.sg\n",
      "tel:777 8100\n",
      "24/7\n",
      "4055\n",
      "5977\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import CharsetMapper\n",
    "\n",
    "charset = CharsetMapper('../data/charset_36.txt', 26)\n",
    "\n",
    "data_dir = '../data/IC15'\n",
    "ic15_training = '../data/ch4_training_word_images_gt'\n",
    "ic15_test = '../data/ch4_test_word_images_gt'\n",
    "ic15_training_gt = os.path.join(ic15_training, 'gt.txt')\n",
    "ic15_test_gt = os.path.join(ic15_test, 'gt.txt')\n",
    "\n",
    "def convert_ic15_gt_file(gt_path: str, output_path: str, image_dir: str):\n",
    "    with open(gt_path, 'r', encoding='utf-8-sig') as f:\n",
    "        lines = f.readlines()\n",
    "        pattern = re.compile(r'^(.*?), \"(.*?)\"$')\n",
    "        results = []\n",
    "        for line in lines:\n",
    "            match = pattern.match(line)\n",
    "            if match:\n",
    "                img, text = match.group(1), match.group(2)\n",
    "                text = text.lower()\n",
    "                charset_values = charset.label_to_char.values()\n",
    "                if not all([c in charset_values for c in text]):\n",
    "                    continue\n",
    "                # # remove characters not in charset\n",
    "                # text = ''.join([c for c in text.lower() if c in charset_values])\n",
    "                # if len(text) == 0:\n",
    "                #     continue\n",
    "                results.append((img, text))\n",
    "            else:\n",
    "                raise Exception(\"Wrong format\")\n",
    "            \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for img, text in results:\n",
    "            f.write(f'{image_dir}{img}\\t{text}\\n')\n",
    "\n",
    "convert_ic15_gt_file(ic15_training_gt, os.path.join(data_dir, 'train.txt'), 'train/')\n",
    "convert_ic15_gt_file(ic15_test_gt, os.path.join(data_dir, 'test.txt'), 'test/')\n",
    "\n",
    "lines = []\n",
    "with open(os.path.join(data_dir, 'train.txt'), 'r', encoding='utf-8') as f:\n",
    "    lines.extend(f.readlines())\n",
    "    print(len(lines))\n",
    "\n",
    "with open(os.path.join(data_dir, 'test.txt'), 'r', encoding='utf-8') as f:\n",
    "    lines.extend(f.readlines())\n",
    "    print(len(lines))\n",
    "\n",
    "with open(os.path.join(data_dir, 'labels.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.writelines(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import CharsetMapper\n",
    "\n",
    "charset = CharsetMapper('../data/charset_36.txt', 26)\n",
    "\n",
    "data_dir = '../data/IIIT5k'\n",
    "iiit5k_train_org = os.path.join(data_dir, 'train_org.txt')\n",
    "iiit5k_test_org = os.path.join(data_dir, 'test_org.txt')\n",
    "\n",
    "def filter_iiit5k(gt_path: str, output_path: str):\n",
    "    with open(gt_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        results = []\n",
    "        for line in lines:\n",
    "            img, text = line.strip().split()\n",
    "            text = text.lower()\n",
    "            charset_values = charset.label_to_char.values()\n",
    "            if not all([c in charset_values for c in text.lower()]):\n",
    "                continue\n",
    "            # # remove characters not in charset\n",
    "            # text = ''.join([c for c in text if c in charset_values])\n",
    "            # if len(text) == 0:\n",
    "            #     continue\n",
    "            results.append((img, text))\n",
    "            \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for img, text in results:\n",
    "            f.write(f'{img}\\t{text}\\n')\n",
    "\n",
    "filter_iiit5k(iiit5k_train_org, os.path.join(data_dir, 'train.txt'))\n",
    "filter_iiit5k(iiit5k_test_org, os.path.join(data_dir, 'test.txt'))\n",
    "\n",
    "lines = []\n",
    "with open(os.path.join(data_dir, 'train.txt'), 'r', encoding='utf-8') as f:\n",
    "    lines.extend(f.readlines())\n",
    "    print(len(lines))\n",
    "\n",
    "with open(os.path.join(data_dir, 'test.txt'), 'r', encoding='utf-8') as f:\n",
    "    lines.extend(f.readlines())\n",
    "    print(len(lines))\n",
    "\n",
    "with open(os.path.join(data_dir, 'labels.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.writelines(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_line(line, data_dir, max_length, chars):\n",
    "    parts = line.strip().split()\n",
    "    assert len(parts) == 2\n",
    "    img_file, _ = parts\n",
    "    label = img_file.split('_')[1]\n",
    "    img_path = os.path.join(data_dir, img_file)\n",
    "    if not os.path.exists(img_path):\n",
    "        return None\n",
    "    try:\n",
    "        Image.open(img_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {img_file}: {e}\")\n",
    "        return None\n",
    "    if len(label) <= max_length and (not chars or any(c in label for c in chars)):\n",
    "        return line\n",
    "    return None\n",
    "\n",
    "def filter_by_length(input_file, output_file, max_length, data_dir=None, chars=None):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        lines = infile.readlines()\n",
    "        filtered_lines = []\n",
    "        \n",
    "        # Use ThreadPoolExecutor to filter lines in parallel\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "            future_to_line = {executor.submit(filter_line, line, data_dir, max_length, chars): line for line in lines}\n",
    "            for future in tqdm(concurrent.futures.as_completed(future_to_line), total=len(lines)):\n",
    "                filtered_line = future.result()\n",
    "                if filtered_line:\n",
    "                    filtered_lines.append(filtered_line)\n",
    "\n",
    "        # for line in tqdm(lines):\n",
    "        #     parts = line.strip().split()\n",
    "        #     assert len(parts) == 2\n",
    "        #     img_file, _ = parts\n",
    "        #     label = img_file.split('_')[1]\n",
    "        #     if data_dir and not os.path.exists(os.path.join(data_dir, img_file)):\n",
    "        #         continue\n",
    "        #     try:\n",
    "        #         Image.open(os.path.join(data_dir, img_file))\n",
    "        #     except Exception as e:\n",
    "        #         print(f\"Error opening image {img_file}: {e}\")\n",
    "        #         continue\n",
    "        #     if len(label) <= max_length:\n",
    "        #         if chars and not any(c in label for c in chars):\n",
    "        #             continue\n",
    "        #         filtered_lines.append(line)\n",
    "        outfile.writelines(filtered_lines)\n",
    "        print(f\"Filtered {len(lines)} lines to {len(filtered_lines)} lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filter_by_length('data/mnt/ramdisk/max/90kDICT32px/annotation_train.txt', 'data/mnt/ramdisk/max/90kDICT32px/annotation_train_ml13.txt', 13, 'data/mnt/ramdisk/max/90kDICT32px')\n",
    "filter_by_length('data/mnt/ramdisk/max/90kDICT32px/annotation_test.txt', 'data/mnt/ramdisk/max/90kDICT32px/annotation_test_ml13.txt', 13, 'data/mnt/ramdisk/max/90kDICT32px')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872818\n",
      "872817\n"
     ]
    }
   ],
   "source": [
    "with open('../data/mnt/ramdisk/max/90kDICT32px/annotation_test_ml13.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    print(len(lines))\n",
    "\n",
    "with open('../data/mnt/ramdisk/max/90kDICT32px/annotation_test_ml13_clean.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    print(len(lines))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
